<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MySQL on 道法自然</title>
    <link>/tags/mysql/</link>
    <description>Recent content in MySQL on 道法自然</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/mysql/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Database Sharding</title>
      <link>/blog/2019/19-03-09-database-sharding/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-03-09-database-sharding/</guid>
      <description>Sharding 可以简单地认为Sharding就是对数据进行分组的过程，即将整个大的数据集按照某种规则分割成多个小数据集。类似于网站服务，针对不同的服务，提供服务的链接地址也不相同，而这其实也是一个Sharding的过程。在业务层实现的Sharding，关键就在Route的过程，即将具体的数据请求，发送到对的数据集上。
Why Sharding 在一些本地缓存的开发中，如果以map的形式存储数据集，因为该类型不支持并发操作。所以，在读写操作时就需要对map进行加锁，。可想而知，每次操作都加锁、解锁，而读写缓存又是一个高频操作，性能当然上不去。解决的思路就是对数据集进行Sharding操作，将整个数据集拆分成多个小块数据集，这样分别对小块数据集进行加锁、解锁，性能就提高了不少。
如果数据集过大，表的检索性能会越来越低。而如果对数据集进行分片，对分片数据并发检索，以及将某些分片数据直接加载到内存，都可以极大提高操作的效率。
数据均匀分布 拿博客网站举例，老用户发布的博客肯定要多于新注册的用户。那么，在对博客记录进行分表操作时，就需要考虑数据均匀分布的问题，避免老用户都分布在一张表内，造成这张表数据额外大。
解决的办法很简单，即对Sharding Key先做Hash处理，然后再实现数据Sharding过程。比如在系统设计初期，我们考虑基于用户UID将博客数据拆分成4个表。最基础的分表策略：
// 最终的结果就是blog_0, blog_1, blog_2, blog_3 tablePrefix := blog_%d tableName := fmt.Sprintf(&amp;quot;%s&amp;quot;, uid&amp;amp;3)  业务类型 分表过程需要结合实际项目，不同的业务场景，需求千差万别、更别说底层的数据了。拿购物场景来说，以商铺为分表Key，将同商铺的交易数据存储到一起，跟以用户为分表Key，将同用户的交易数据存储到一起。这两种情形完全不同，而这也将决定项目后期数据统计的方式。
所以分区的根本再于业务要执行的具体数据操作，要知道跨分区来之行Join之类的操作，不仅处理麻烦，性能也是问题。
服务化 实际项目中，按单一维度划分业务数据几乎是不可能的。比如上面说到的购物场景，商铺是一个维度，用户同样也是一个维度，当然，产品的类型还是一个维度。
这种情况下，我们一般选择将项目拆分成多个微服务，划分各个微服务间操作数据的边界范围。而服务与服务间的数据交互都通过调用API来实现。
需要注意的是，服务拆分一定要从具体业务来考虑，尽可能将关联数据保存在同一个物理节点，避免每次操作都需要通过网络来发送大量的数据。
唯一ID 将数据集划分为多个分区后，基于不同的业务，查询场景也会面临各种各样的问题。比如在博客网站中，假设我们基于用户做了Sharding分表，而查询需求是：按照博客的发布时间顺序来展示列表。所以，这样的分页查询会异常痛苦。假设列表每页展示20条记录，那么代码就需要从每张表中都取出最近的20条记录做merge处理。如果Sharding的个数足够多，那简直无法继续了。
-- 获取最新的20条发帖记录。如果要翻页的话，将Now替换为上一批数据的最早时间 select * from blog_0 where create_time &amp;lt; Now() order by id desc; select * from blog_1 where create_time &amp;lt; Now() order by id desc; select * from blog_2 where create_time &amp;lt; Now() order by id desc; select * from blog_3 where create_time &amp;lt; Now() order by id desc;  正确的处理方式是创建一张关系表，记录所有博客元信息。而上述分页操作都基于该关系表来实现。但Sharding中的各表都有各自的自增主键，都从1开始自增，这就导致各个表中存在相同的标识符，再关系表中无法做区分。解决的办法大致有两种：</description>
    </item>
    
    <item>
      <title>Deafult Decimal</title>
      <link>/blog/2018/12-01-deafult-decimal/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/12-01-deafult-decimal/</guid>
      <description>版本 0.00
 我说：version dependent 表示我们的思考时，应该依赖具体的版本。举个例子，你把2015年看到的一些redis机制拿到现在跟别人谈论，很容易闹出笑话。在3年的时间里，它可能已经做了无数的优化。所以，思考要与时俱进。
 引言 在涉及到支付业务的时候，数据库里的钱怎么存：  存储单位是元。在业务处理的时候就会涉及到浮点数，很多商家喜欢将价钱定义为0.99而不是1元。这在使用过程中非常忌讳是否相等的比较。浮点数的比较经常喜欢用|floatA - floatB| &amp;gt; 0.00001来，很多第三方库也提供了比较方法。 存储单位时分。为了避免浮点类型比较时的不确定性，决定使用整形来替代。一般来说没有问题，可如果是要严格缺心眼打折，比如给一个售价4.99的打5折，那么最后就会存在5里的情况。一般都喜欢向上取整，应收用户2.495，实收用户2.50.  那么在MySQL的Column中该如何存储呢？  如果是分的话，肯定时当整形来存储的。但如果时浮点的，大家都会选择decimal，因为该类型不会丢失精度。 存储为字符串。浮点数保留指定位数的字符串。在Go中我也尝试过，fmt.Sprintf(&amp;quot;%.2f&amp;quot;, 3.091)还是靠谱的。  这篇文章当然不是来分析这两种存储方式的，也不是来分析该存储什么数据类型的。而仅仅时想阐述一个之前不了解的知识点（知识点太少，写点别的来凑）。
deault value 在MySQL建表的过程中，一般都会指定DEFAULT VALUE。在执行INSERT时，如果不指定该字段，MySQL会默认使用该默认值来替代。下面是创建的一个decimal类型字段，在Go中使用xorm 来表示，可以看出，xorm使用字符串类型来接收decimal类型的值。
type table_test struct { PayPrice string `xorm:&amp;quot;not null default 0.00 comment(&#39;支付价钱&#39;) DECIMAL(10,2)&amp;quot;` }  最后发现：在测试环境下，向数据库插入记录时，不指定PayPrice没有任何问题。但到了正式服数据表插入便失败了。报错信息如下：
{ &amp;quot;Number&amp;quot;: 1366, &amp;quot;Message&amp;quot;: &amp;quot;Incorrect decimal value: &#39;&#39; for column &#39;pay_price&#39; at row 1&amp;quot; }  STRICT_TRANS_TABLES 查询sql_mode如下：
show variables like &#39;sql_mode&#39;  下面的内容截取至:Strict SQL Mode:</description>
    </item>
    
    <item>
      <title>MySQL事务</title>
      <link>/blog/2018/07-01-mysql%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/07-01-mysql%E4%BA%8B%E5%8A%A1/</guid>
      <description>关于MySQL事务的诡异问题，至今没有调查出原因。但却也是一个契机，带我重新回忆之前的遇到的事务问题。
诡异的问题 系统中存在A和B两个表。B表中有两个关键字段：一个是唯一索引transaction_id，还有一个是标识处理状态的status。当status=0表示记录未被处理，status=1表示记录处理过了，不需要再处理了。
如果B中记录未处理，则在A表中插入一条权益记录，同时更新status=1，后续就不能再给用户加权益了。
代码做了如下处理：
func sessPart() { //开启事务 session := engine.NewSession() sess.Begin() defer session.Close() defer sess.Rollback() //插入价钱100分的权益交付记录 exchange := models.Exchange{Money: 100, Uid: 1} _, err := sess.Insert(exchange) if err != nil { sess.Rollback() return } //更新status为1 //并且使用乐观锁，防止因没有匹配到数据，直接返回成功 testModel := Test{ Status: 1, } affectRows, err := sess.Where(&amp;quot;transaction_id = ? AND status = 0&amp;quot;, 1). Cols(&amp;quot;status&amp;quot;).Update(&amp;amp;testModel) if err != nil || affectRows == 0 { sess.Rollback() return } sess.Commit() } //测试事务的并发情况 func BenchmarkLock(b *testing.</description>
    </item>
    
    <item>
      <title>MySQL使用总结(一)</title>
      <link>/blog/2018/05-09-mysql%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E4%B8%80-/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/05-09-mysql%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E4%B8%80-/</guid>
      <description>查询的执行时间 第一次遇到查询时候报超时。很好奇，别的工具是如何修改查询的操时时间。
set max_statement_time = 0;  By using max_statement_time, it is possible to limit the execution time of individual queries.
 The MySQL version of max_statement_time is defined in millseconds, not seconds. MySQL&amp;rsquo;s implementation can only kill SELECTs.  left join 这个语句执行起来特别的费劲，但需求是：找出A表中存在，但B表中不存在的记录。
on条件 一直以为on是在执行表关联时的判断逻辑，即两个表的记录要不要关联，全靠on。直到遇到left join。发现它完全没有理会on提供的左表过滤条件，它返回了左表的全部记录，需要将条件放到where中才生效。
举个例子
-- table_a.id &amp;gt; 2018 无效 select * from table_a left join table_b on table_a.id = table_b.a_id and table_a.id &amp;gt; 2018 -- 正确的方式 select * from table_a left join table_b on table_a.</description>
    </item>
    
  </channel>
</rss>