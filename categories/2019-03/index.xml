<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2019-03 on 道法自然</title>
    <link>/categories/2019-03/</link>
    <description>Recent content in 2019-03 on 道法自然</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/2019-03/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Go 调度模型（一）</title>
      <link>/blog/2019/19-03-24-go-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B%E4%B8%80/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-03-24-go-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B%E4%B8%80/</guid>
      <description>题：想清楚了就去做，做的时候不要再回头想。
 OS Scheduler 在操作系统中保存了运行的进程列表，以及进程的运行状态(运行中、可运行及不可运行)。当进程运行时长超过了被分配的时间片(比如每10ms)，那么该进程会被系统抢占，然后在该CPU上执行别的进程。所以，OS的调度是抢占式的，可能抢占策略略有不同。
当进程被抢占时，需要保存该进程运行的上下文，并被重新放回到调度器，等待下一次被执行。
Golang Scheduler  Goroutine scheduler
The scheduler&amp;rsquo;s job is to distribute ready-to-run goroutines over worker threads.
 如图所示，OS层看到是只有Go进程以及运行的多个线程，而Goroutine本身是被Golang Runtime Scheduler调度管理的。
对OS而言，Go Binary是一个系统进程。内部Go Program对系统API的调度都是通过Runtime level解释来实现。Runtine记录了每个Goroutine的信息，在当前进程的线程池中按照顺序依次调度Goroutine。
Golang在Runtime内部实现了自己的调度，并不是基于时间切片的抢占式调度，而是基于Goroutines的协作式调度，目的就是要让Goroutine在OS-Thread中发挥出更多的并发优势。所以，在Runtime过程中，只有当正在运行的Goroutine被阻塞或者运行结束时，别的Goroutine才会被调度。常见的阻塞情形包括：
 阻塞的系统调用方式，比如文件或网络操作 垃圾自动回收  整体而言，Goroutine的数量大于Threads数量会更有优势，这样当其他Goroutine阻塞时，别的Goroutine就会被执行。
Goroutine G用于表示Goroutine及它所包含的栈和状态信息。Goroutine存在于Go Runtime的的虚拟空间，而非OS中。
// src/runtime/runtime2.go // 以下结构体精简了很多字段 type g struct { stack stack // offset known to runtime/cgo m *m // current m; offset known to arm liblink sched gobuf stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.</description>
    </item>
    
    <item>
      <title>无聊的自我期待</title>
      <link>/life/2019/19-03-24-%E6%97%A0%E8%81%8A%E7%9A%84%E8%87%AA%E6%88%91%E6%9C%9F%E5%BE%85/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/life/2019/19-03-24-%E6%97%A0%E8%81%8A%E7%9A%84%E8%87%AA%E6%88%91%E6%9C%9F%E5%BE%85/</guid>
      <description>我慢慢明白了我为什么不快乐，因为我总是期待一个结果。
 事情并不会按你的意愿去发展 每一个买彩票的人，或者在被抽奖之前，都觉得自己是天选之人。然而，这样的个人意愿甚至至今都没能实现。客观理性的讲，无须执着低概率的事情，由它去吧，脑补它的结果，没有任何意义。
这种幻想发横财的事情如此，真实的世界亦如此。
人与人之间，如果不存在某种特殊关系，比如上下级，那么任何人没有义务执行你的设定。毕竟人是有主观想法的高等动物，有时候不给你使坏就很好很好了。</description>
    </item>
    
    <item>
      <title>数据一致性（二）</title>
      <link>/blog/2019/19-03-16-%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E4%BA%8C/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-03-16-%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E4%BA%8C/</guid>
      <description>我们流连于事物的表象，满足浅尝辄止的片刻欢愉，却几乎从不久留。我们在人生的道路上争先恐后，却吝于用片刻思考目标和方向。
 概述 至今没有接触过MySQL多主的情况，即存在多个MySQL实例同时负责读写请求（抛弃只读库）。思考后认为：没有这么实现的技术难点在于：数据的一致性得不到保证。此外，还会涉及：
 MySQL采用自增主键索引的话，多主之间的数据同步简直是灾难。 内部锁机制的优势大打折扣，跨主库间的锁应该也是灾难级别的吧。  那么支持分布式的其他数据库又是怎么搞定这个问题的呢？比如Cassandra，多个节点之间可以同时处理读写请求，那么它是如何处理节点间数据同步以保证一致性的呢？
MySQL数据的一致性  We think this is an unacceptable burden to place ondevelopers and that consistency problems should be solved at the database level
 细细想想，MySQL自身实现的数据一致性也是相当复杂的。以Innodb举例，如果通过普通索引执行查询，首先获取到的仅仅是主键索引，后面还需要通过主键索引来获取完整的记录。查询如此，更新亦如此。
Master-Slave模式 通常情况下，MySQL部署都是一主多从。Master作为更新DB的入口，而Slave的数据通过binlog来进行同步。所以大胆想一想，有没有可能出现一种情况（假设id=1记录原始的name值为neojos）：
## 第一次同步数据 update s-1 set name=&amp;quot;neojos-1&amp;quot; where id = 1; ## 失败 update s-2 set name=&amp;quot;neojos-1&amp;quot; where id = 1; ## 成功 update s-3 set name=&amp;quot;neojos-1&amp;quot; where id = 1; ## 成功 ## 第二次同步数据 update s-1 set name=&amp;quot;neojos-2&amp;quot; where id = 1; ## 成功 update s-2 set name=&amp;quot;neojos-2&amp;quot; where id = 1; ## 失败 update s-3 set name=&amp;quot;neojos-2&amp;quot; where id = 1; ## 成功  最后，数据库从某一个时间点开始，Master和Salve的数据会变得不一致了当然不可能，MySQL在数据同步上做了非常硬的约束。包括Slave_IO_Running、Slave_SQL_Running以及Seconds_Behind_Master等。</description>
    </item>
    
    <item>
      <title>平常心</title>
      <link>/life/2019/19-03-12-%E5%B9%B3%E5%B8%B8%E5%BF%83/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/life/2019/19-03-12-%E5%B9%B3%E5%B8%B8%E5%BF%83/</guid>
      <description>愿你在所得少于付出时，不会终日愤愤；愿你在所得超过付出时，不必终日惶恐。
—— 东野圭吾
 一切都很准时  New York is 3 hours ahead of California
But it does not make California slow
Someone graduated at the age of 22
but waited 5 years before securing a good job
Someone become a CEO at 25
and died at 50
while another become a CEO at 50
and lived to 90 years
Someone is still single
while someone else got married</description>
    </item>
    
    <item>
      <title>Database Sharding</title>
      <link>/blog/2019/19-03-09-database-sharding/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-03-09-database-sharding/</guid>
      <description>Sharding 可以简单地认为Sharding就是对数据进行分组的过程，即将整个大的数据集按照某种规则分割成多个小数据集。类似于网站服务，针对不同的服务，提供服务的链接地址也不相同，而这其实也是一个Sharding的过程。在业务层实现的Sharding，关键就在Route的过程，即将具体的数据请求，发送到对的数据集上。
基本要求：Sharding前后执行相同的查询，返回的结果也相同。
Why Sharding 在一些本地缓存的开发中，如果以map的形式存储数据集，因为该类型不支持并发操作。所以，在读写操作时就需要对map进行加锁，。可想而知，每次操作都加锁、解锁，而读写缓存又是一个高频操作，性能当然上不去。解决的思路就是对数据集进行Sharding操作，将整个数据集拆分成多个小块数据集，这样分别对小块数据集进行加锁、解锁，性能就提高了不少。
如果数据集过大，表的检索性能会越来越低。而如果对数据集进行分片，对分片数据并发检索，以及将某些分片数据直接加载到内存，都可以极大提高操作的效率。
数据均匀分布 拿博客网站举例，老用户发布的博客肯定要多于新注册的用户。那么，在对博客记录进行分表操作时，就需要考虑数据均匀分布的问题，避免老用户都分布在一张表内，造成某张表数据额外大。
解决的办法很简单，即对Sharding Key先做Hash处理，然后再实现数据Sharding过程。比如在系统设计初期，我们考虑基于用户UID将博客数据拆分成4个表。最基础的分表策略：
// 最终的结果就是blog_0, blog_1, blog_2, blog_3 tablePrefix := blog_%d tableName := fmt.Sprintf(&amp;quot;%s&amp;quot;, uid&amp;amp;3)  业务类型 分表过程需要结合实际项目，不同的业务场景，需求千差万别、更别说底层的数据了。拿购物场景来说，以商铺为分表Key，将同商铺的交易数据存储到一起，跟以用户为分表Key，将同用户的交易数据存储到一起。这两种情形完全不同，而这也将决定项目后期数据统计的方式。
所以分区的根本再于业务要执行的具体数据操作，要知道跨分区来之行Join之类的操作，不仅处理麻烦，性能也是问题。
服务化 实际项目中，按单一维度划分业务数据几乎是不可能的。比如上面说到的购物场景，商铺是一个维度，用户同样也是一个维度，当然，产品的类型还是一个维度。
这种情况下，我们一般选择将项目拆分成多个微服务，划分各个微服务间操作数据的边界范围。而服务与服务间的数据交互都通过调用API来实现。
需要注意的是，服务拆分一定要从具体业务来考虑，尽可能将相关的数据放在一起，提高检索性能，避免每次操作都需要通过网络来发送数据。
唯一ID 将数据集划分为多个分区后，基于不同的业务，查询场景也会面临各种各样的问题。比如在博客网站中，假设我们基于用户做了Sharding分表，而查询需求是：按照博客的发布时间顺序来展示列表。所以，这样的分页查询会异常痛苦。假设列表每页展示20条记录，那么代码就需要从每张表中都取出最近的20条记录做merge处理。如果Sharding的个数足够多，那简直无法继续了。
-- 获取最新的20条发帖记录。如果要翻页的话，将Now替换为上一批数据的最早时间 select * from blog_0 where create_time &amp;lt; Now() order by id desc; select * from blog_1 where create_time &amp;lt; Now() order by id desc; select * from blog_2 where create_time &amp;lt; Now() order by id desc; select * from blog_3 where create_time &amp;lt; Now() order by id desc;  正确的处理方式是创建一张关系表，记录所有博客元信息。而上述分页操作都基于该关系表来实现。但Sharding中的各表都有各自的自增主键，都从1开始自增，这就导致各个表中存在相同的标识符，再关系表中无法做区分。解决的办法大致有两种：</description>
    </item>
    
    <item>
      <title>读书有感</title>
      <link>/life/2019/19-03-03-%E8%AF%BB%E4%B9%A6%E6%9C%89%E6%84%9F/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/life/2019/19-03-03-%E8%AF%BB%E4%B9%A6%E6%9C%89%E6%84%9F/</guid>
      <description>19年开始读一些文学书，内心多了30的焦虑，希望从别人的故事中汲取力量。
 创业，从一个小目标开始 创办了zendesk的企业家写的一本回忆录，从透支信用卡、挤经济舱到开全球限量版轿车、坐私人飞机，其中的艰辛只有他自己最清楚。作为一个看客，最触动我的便是：他们年过30，随便去任何一家公司都能领到不错的薪水，但还是毅然决然地选择了自己创业，他们的理由很简单，如果这次创业机会不能好好把握，自己的人生便是死局。
创业，可能是每个有梦想的人都必须走的一条路吧。</description>
    </item>
    
  </channel>
</rss>