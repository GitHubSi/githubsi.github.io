<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2019-06 on 渐行渐远</title>
    <link>/categories/2019-06/</link>
    <description>Recent content in 2019-06 on 渐行渐远</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 22 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/2019-06/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using context cancellation in Go</title>
      <link>/blog/2019/19-06-23-using-context-cancellation-in-go/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-06-23-using-context-cancellation-in-go/</guid>
      <description>文章介绍最近工作中遇到的一个问题，其中50%以上的内容都是Go的源代码。剩下部分是自己的理解，如果有理解错误或探讨的地方，希望大家指正。
问题：针对同一个接口请求，绝大多数都可以正常处理，但却有零星的几请求老是处理失败，错误信息返回 context canceled。重放失败的请求，错误必现。
根据返回的错误信息，再结合我们工程中使用的golang.org/x/net/context/ctxhttp包。猜测可能是在请求处理过程中，异常调用了context 包的CancelFunc方法。同时，我们对比了失败请求和成功请求的区别，发现失败请求的Response.Body数据量非常大。
之后在Google上找到了问题的原因，还真是很容易被忽略，这里是文章的链接：Context cancellation flake。为了解决未来点进去404的悲剧，本文截取了其中的代码&amp;hellip;
Code 代码核心逻辑：向某个地址发送Get请求，并打印响应内容。其中函数fetch用于发送请求，readBody用于读取响应。例子中处理请求的逻辑结构，跟我们项目中的完全一致。
fetch方法中使用了默认的http.DefaultClient作为http Client，而它自身是一个“零值”，并没有指定请求的超时时间。所以，例子中又通过context.WithTimeout对超时时间进行了设置。
代码中使用context.WithTimeout来取消请求，存在两种可能情况。第一种，处理的时间超过了指定的超时时间，程序返回deadlineExceededError错误，错误描述context deadline exceeded。另一种是手动调用CancelFunc方法取消执行，返回Canceled错误，描述信息context canceled。
在fetch代码的处理逻辑中，当程序返回http.Response时，会执行cancel()方法，用于标记请求被取消。如果在readBody没读取完返回的数据之前，context被cancel掉了，就会返回context canceled错误。侧面也反映了，关闭Context.Done()与读取http.Response是一个时间赛跑的过程…..
package main import ( &amp;quot;context&amp;quot; &amp;quot;io/ioutil&amp;quot; &amp;quot;log&amp;quot; &amp;quot;net/http&amp;quot; &amp;quot;time&amp;quot; &amp;quot;golang.org/x/net/context/ctxhttp&amp;quot; ) func main() { req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;https://swapi.co/api/people/1&amp;quot;, nil) if err != nil { log.Fatal(err) } resp, err := fetch(req) if err != nil { log.Fatal(err) } log.Print(readBody(resp)) } func fetch(req *http.Request) (*http.Response, error) { ctx, cancel := context.WithTimeout(context.Background(), 5*time.</description>
    </item>
    
    <item>
      <title>里氏替换&amp;开放关闭</title>
      <link>/blog/2019/19-06-06-%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%BC%80%E6%94%BE%E5%85%B3%E9%97%AD/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-06-06-%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%BC%80%E6%94%BE%E5%85%B3%E9%97%AD/</guid>
      <description>里氏替换  Let Φ(x) be a property provable about objects x of type T. Then Φ(y) should be true for objects y of type S where S is a subtype of T
 本质上就是类设计中的继承，它强调类所实现的行为。参数的类型指定为基类，而实际传参的时候使用具体的子类。每次扩展新的行为，都通过创建一个新的子类来实现。在Go的设计中，继承是通过接口类型来实现的。
开放关闭  Software entities (classes, modules, function, etc) should be open for extension, but closed for modification.
A class is closed, since it may be complied, stored in a library, baselined and used by client classes.</description>
    </item>
    
    <item>
      <title>database package</title>
      <link>/blog/2019/19-06-03-database-package/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-06-03-database-package/</guid>
      <description>清除无效连接 在database库下清除过期连接时，使用了如下的代码逻辑。其中freeConn是空闲连接池，d是连接可被重复使用的最长时间，nowFunc返回的是当前时间。最新生成的连接在freeConn的末尾，而清除的过程则是使用最新的、次新的连接依次替换最早过期的、次早过期的连接。
在for循环中直接使用len来获取总计数，在循环体内部将freeConn末尾的值替换首部的值，并将freeConn的len长度减去1。最后还做了i—操作，重复校验了一次。
expiredSince := nowFunc().Add(-d) var closing []*driverConn for i := 0; i &amp;lt; len(db.freeConn); i++ { c := db.freeConn[i] if c.createdAt.Before(expiredSince) { closing = append(closing, c) last := len(db.freeConn) - 1 db.freeConn[i] = db.freeConn[last] db.freeConn[last] = nil db.freeConn = db.freeConn[:last] i-- } }  参考点 slice中首部和尾部数据的交换过程，以及每次通过i--达到的重复校验的思路。
间隔执行 清除无效连接的工作是由一个goroutine在后台完成的，下面是截取的部分代码。for循环内部是处理连接的具体实现。每次清除操作完成后，通过Reset来重置Timer。
func (db *DB) connectionCleaner(d time.Duration) { const minInterval = time.Second if d &amp;lt; minInterval { d = minInterval } t := time.</description>
    </item>
    
    <item>
      <title>mongo中ObjectId</title>
      <link>/blog/2019/19-06-11-mongo%E4%B8%ADobjectid/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/19-06-11-mongo%E4%B8%ADobjectid/</guid>
      <description>ObjectId在mongo中是自动生成的_id字段，充当数据表的主键ID。按照_id排序基本上等于按照记录的创建时间排序，但还是必须注意：_id并不是严格单调递增的，前4个byte的也只是精确到了秒级，同一秒内的_id并不能保证有序。
 ObjectIds are small, likely unique, faster to generate, and ordered. ObjectId values consist of 12 bytes, where the first four bytes are a timestamp that reflect the objectId&amp;rsquo;s creation. Specifically - a 4-byte value representing the seconds since the Unix epoch - a 5-byte random value - a 3 byte counter, starting with a random value
 排序 使用github.com/globalsign/mgo的翻页逻辑：
func (detail *CounterDetailMapper) GetDetailsByDesc(ctx context.IContext, objectId string, size int, startPoint string, data *[]models.</description>
    </item>
    
  </channel>
</rss>